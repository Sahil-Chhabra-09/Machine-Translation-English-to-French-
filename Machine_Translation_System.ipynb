{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1h4srTI6uQnlTlCiZdamFvY7PB88JQwxq",
      "authorship_tag": "ABX9TyMmdYVlYYHKy/kpnLfeHUNn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sahil-Chhabra-09/Machine-Translation-English-to-French-/blob/main/Machine_Translation_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing A Machine Translation System which translates English to using English and French word embeddings"
      ],
      "metadata": {
        "id": "Tg3hYAeHXuuL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2qvTTdbXO6H",
        "outputId": "19081bc3-554d-41ce-9040-1604bb7bc473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "def process_tweet(tweet):\n",
        "    '''\n",
        "    Input:\n",
        "        tweet: a string containing a tweet\n",
        "    Output:\n",
        "        tweets_clean: a list of words containing the processed tweet\n",
        "\n",
        "    '''\n",
        "    stemmer = PorterStemmer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "    # remove stock market tickers like $GE\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "    # remove old style retweet text \"RT\"\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    # remove hyperlinks\n",
        "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "    # remove hashtags\n",
        "    # only removing the hash # sign from the word\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "    # tokenize tweets\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
        "                               reduce_len=True)\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "    tweets_clean = []\n",
        "    for word in tweet_tokens:\n",
        "        if (word not in stopwords_english and  # remove stopwords\n",
        "            word not in string.punctuation):  # remove punctuation\n",
        "            # tweets_clean.append(word)\n",
        "            stem_word = stemmer.stem(word)  # stemming word\n",
        "            tweets_clean.append(stem_word)\n",
        "\n",
        "    return tweets_clean\n",
        "\n",
        "\n",
        "def get_dict(file_name):\n",
        "    \"\"\"\n",
        "    This function returns the english to french dictionary given a file where the each column corresponds to a word.\n",
        "    Check out the files this function takes in your workspace.\n",
        "    \"\"\"\n",
        "    my_file = pd.read_csv(file_name, delimiter=' ')\n",
        "    etof = {}  # the english to french dictionary to be returned\n",
        "    for i in range(len(my_file)):\n",
        "        # indexing into the rows.\n",
        "        en = my_file.loc[i][0]\n",
        "        fr = my_file.loc[i][1]\n",
        "        etof[en] = fr\n",
        "\n",
        "    return etof\n",
        "\n",
        "\n",
        "def cosine_similarity(A, B):\n",
        "    '''\n",
        "    Input:\n",
        "        A: a numpy array which corresponds to a word vector\n",
        "        B: A numpy array which corresponds to a word vector\n",
        "    Output:\n",
        "        cos: numerical number representing the cosine similarity between A and B.\n",
        "    '''\n",
        "    # you have to set this variable to the true label.\n",
        "    cos = -10    \n",
        "    dot = np.dot(A, B)\n",
        "    normb = np.linalg.norm(B)\n",
        "    \n",
        "    if len(A.shape) == 1: # If A is just a vector, we get the norm\n",
        "        norma = np.linalg.norm(A)\n",
        "        cos = dot / (norma * normb)\n",
        "    else: # If A is a matrix, then compute the norms of the word vectors of the matrix (norm of each row)\n",
        "        norma = np.linalg.norm(A, axis=1)\n",
        "        epsilon = 1.0e-9 # to avoid division by 0\n",
        "        cos = dot / (norma * normb + epsilon)\n",
        "        \n",
        "    return cos"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### importing a subset of word embeddings of english and french"
      ],
      "metadata": {
        "id": "bvfrKugcYDEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "# a subset of actual embeddings actual embeddings size: 1gb + 729mb\n",
        "en_embeddings_subset = pickle.load(open(\"/content/drive/MyDrive/Word Embeddings English to French/en_embeddings.p\", \"rb\"))\n",
        "fr_embeddings_subset = pickle.load(open(\"/content/drive/MyDrive/Word Embeddings English to French/fr_embeddings.p\", \"rb\"))"
      ],
      "metadata": {
        "id": "i0ERKk0RYGt9"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(en_embeddings_subset.get(\"the\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6HK5EhaYRAe",
        "outputId": "c1efdb43-883d-4bb6-cfd6-7423c1858020"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### importing training and testing mapping of words of english and french\n",
        "\n",
        "```\n",
        "{'the': 'la',\n",
        " 'and': 'et',\n",
        " 'was': 'était',\n",
        " 'for': 'pour',\n",
        "```"
      ],
      "metadata": {
        "id": "TxI29rwZYWDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the english to french dictionaries\n",
        "en_fr_train = get_dict('/content/drive/MyDrive/Word Embeddings English to French/en-fr.train.txt')\n",
        "print('The length of the English to French training dictionary is', len(en_fr_train))\n",
        "en_fr_test = get_dict('/content/drive/MyDrive/Word Embeddings English to French/en-fr.test.txt')\n",
        "print('The length of the English to French test dictionary is', len(en_fr_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1d3dqhAYZ6O",
        "outputId": "e2acb8bc-c1a6-4173-b81c-874cb6579c3f"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the English to French training dictionary is 5000\n",
            "The length of the English to French test dictionary is 1500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating matrices X and Y which contain en_fr_train's corresponding word embeddings"
      ],
      "metadata": {
        "id": "EJJWjrOVY_AB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_matrices(en_fr, french_vecs, english_vecs):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        en_fr: English to French dictionary\n",
        "        french_vecs: French words to their corresponding word embeddings.\n",
        "        english_vecs: English words to their corresponding word embeddings.\n",
        "    Output: \n",
        "        X: a matrix where the columns are the English embeddings.\n",
        "        Y: a matrix where the columns correspong to the French embeddings.\n",
        "        R: the projection matrix that minimizes the F norm ||X R -Y||^2.\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # X_l and Y_l are lists of the english and french word embeddings\n",
        "    X_l = list()\n",
        "    Y_l = list()\n",
        "\n",
        "    # get the english words (the keys in the dictionary) and store in a set()\n",
        "    english_set = set(english_vecs.keys())\n",
        "\n",
        "    # get the french words (keys in the dictionary) and store in a set()\n",
        "    french_set = set(french_vecs.keys())\n",
        "\n",
        "    # store the french words that are part of the english-french dictionary (these are the values of the dictionary)\n",
        "    french_words = set(en_fr.values())\n",
        "\n",
        "    # loop through all english, french word pairs in the english french dictionary\n",
        "    for en_word, fr_word in en_fr.items():\n",
        "\n",
        "        # check that the french word has an embedding and that the english word has an embedding\n",
        "        if fr_word in french_set and en_word in english_set:\n",
        "\n",
        "            # get the english embedding\n",
        "            en_vec = english_vecs[en_word]\n",
        "\n",
        "            # get the french embedding\n",
        "            fr_vec = french_vecs[fr_word]\n",
        "\n",
        "            # add the english embedding to the list\n",
        "            X_l.append(en_vec)\n",
        "\n",
        "            # add the french embedding to the list\n",
        "            Y_l.append(fr_vec)\n",
        "\n",
        "    # stack the vectors of X_l into a matrix X\n",
        "    X = np.vstack(X_l)\n",
        "\n",
        "    # stack the vectors of Y_l into a matrix Y\n",
        "    Y = np.vstack(Y_l)\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return X, Y"
      ],
      "metadata": {
        "id": "g77opU9ZZNWA"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = get_matrices(en_fr_train, fr_embeddings_subset, en_embeddings_subset)"
      ],
      "metadata": {
        "id": "T424f83PZVpm"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(en_fr_train.items()).head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Pnpm54yLZaA7",
        "outputId": "a291d91d-9355-408b-8d53-a7fedae5ecc8"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0       1\n",
              "0   the      la\n",
              "1   and      et\n",
              "2   was   était\n",
              "3   for    pour\n",
              "4  that    cela\n",
              "5  with    avec\n",
              "6  from  depuis\n",
              "7  this      ce\n",
              "8   utc     tuc\n",
              "9   his     son"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-333e7780-539c-4718-a473-352a596c917b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the</td>\n",
              "      <td>la</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>and</td>\n",
              "      <td>et</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>was</td>\n",
              "      <td>était</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>for</td>\n",
              "      <td>pour</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>that</td>\n",
              "      <td>cela</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>with</td>\n",
              "      <td>avec</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>from</td>\n",
              "      <td>depuis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>this</td>\n",
              "      <td>ce</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>utc</td>\n",
              "      <td>tuc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>his</td>\n",
              "      <td>son</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-333e7780-539c-4718-a473-352a596c917b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-333e7780-539c-4718-a473-352a596c917b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-333e7780-539c-4718-a473-352a596c917b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({\n",
        "    'fr':fr_embeddings_subset,\n",
        "    'en':en_embeddings_subset\n",
        "}).head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "KhbCzDcnaDyW",
        "outputId": "41f9bb51-8c76-42eb-de85-b02e5a08f1ac"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                       fr  \\\n",
              "la      [-0.0061825, -0.000943867, -0.00882648, 0.0324...   \n",
              "était   [-0.0341354, 0.042414, -0.0656882, 0.0563061, ...   \n",
              "pour    [0.0426481, 0.0395683, -0.00825683, -0.0214458...   \n",
              "cela    [-0.0662544, -0.0448791, -0.034903, 0.0451009,...   \n",
              "avec    [-0.0279761, 0.0359985, -0.0309898, 0.125742, ...   \n",
              "depuis  [-0.0174121, -0.0528022, -0.0012797, 0.0361534...   \n",
              "ce      [-0.0511668, 0.0277349, -0.0263412, 0.0959811,...   \n",
              "tuc     [-0.0333347, 0.018825, -0.0489634, 0.030913, 0...   \n",
              "son     [-0.00726399, -0.00753992, -0.0426105, 0.08087...   \n",
              "pas     [-0.101177, 0.0425327, -0.0694983, 0.0342949, ...   \n",
              "\n",
              "                                                       en  \n",
              "la                                                    NaN  \n",
              "était                                                 NaN  \n",
              "pour                                                  NaN  \n",
              "cela                                                  NaN  \n",
              "avec                                                  NaN  \n",
              "depuis                                                NaN  \n",
              "ce                                                    NaN  \n",
              "tuc                                                   NaN  \n",
              "son     [0.107910156, -0.030029297, 0.033203125, -0.16...  \n",
              "pas                                                   NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e6c7916-ae30-4453-b9cb-2ce308a15c7b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fr</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>la</th>\n",
              "      <td>[-0.0061825, -0.000943867, -0.00882648, 0.0324...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>était</th>\n",
              "      <td>[-0.0341354, 0.042414, -0.0656882, 0.0563061, ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pour</th>\n",
              "      <td>[0.0426481, 0.0395683, -0.00825683, -0.0214458...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cela</th>\n",
              "      <td>[-0.0662544, -0.0448791, -0.034903, 0.0451009,...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>avec</th>\n",
              "      <td>[-0.0279761, 0.0359985, -0.0309898, 0.125742, ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>depuis</th>\n",
              "      <td>[-0.0174121, -0.0528022, -0.0012797, 0.0361534...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ce</th>\n",
              "      <td>[-0.0511668, 0.0277349, -0.0263412, 0.0959811,...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tuc</th>\n",
              "      <td>[-0.0333347, 0.018825, -0.0489634, 0.030913, 0...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>son</th>\n",
              "      <td>[-0.00726399, -0.00753992, -0.0426105, 0.08087...</td>\n",
              "      <td>[0.107910156, -0.030029297, 0.033203125, -0.16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pas</th>\n",
              "      <td>[-0.101177, 0.0425327, -0.0694983, 0.0342949, ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e6c7916-ae30-4453-b9cb-2ce308a15c7b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e6c7916-ae30-4453-b9cb-2ce308a15c7b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e6c7916-ae30-4453-b9cb-2ce308a15c7b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing Gradient Descent fo find Transformation matrix\n",
        "XR ~ Y"
      ],
      "metadata": {
        "id": "c34ogrdAauwg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ L(X, Y, R)=\\frac{1}{m}\\sum_{i=1}^{m} \\sum_{j=1}^{n}\\left( a_{i j} \\right)^{2}$$"
      ],
      "metadata": {
        "id": "lZc2IZDmbDxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(X, Y, R):\n",
        "    '''\n",
        "    Inputs: \n",
        "        X: a matrix of dimension (m,n) where the columns are the English embeddings.\n",
        "        Y: a matrix of dimension (m,n) where the columns correspong to the French embeddings.\n",
        "        R: a matrix of dimension (n,n) - transformation matrix from English to French vector space embeddings.\n",
        "    Outputs:\n",
        "        L: a matrix of dimension (m,n) - the value of the loss function for given X, Y and R.\n",
        "    '''\n",
        "    ### START CODE HERE ###\n",
        "    # m is the number of rows in X\n",
        "    m = X.shape[0]\n",
        "        \n",
        "    # diff is XR - Y    \n",
        "    diff = np.dot(X,R) - Y\n",
        "\n",
        "    # diff_squared is the element-wise square of the difference    \n",
        "    diff_squared = diff**2\n",
        "\n",
        "    # sum_diff_squared is the sum of the squared elements\n",
        "    sum_diff_squared = np.sum(diff_squared)\n",
        "\n",
        "    # loss i is the sum_diff_squared divided by the number of examples (m)\n",
        "    loss = sum_diff_squared/m\n",
        "    ### END CODE HERE ###\n",
        "    return loss"
      ],
      "metadata": {
        "id": "vsHFmUjWayPu"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\\frac{d}{dR}𝐿(𝑋,𝑌,𝑅)=\\frac{d}{dR}\\Big(\\frac{1}{m}\\| X R -Y\\|_{F}^{2}\\Big) = \\frac{2}{m}X^{T} (X R - Y)$$"
      ],
      "metadata": {
        "id": "g4Chckeba9_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient(X, Y, R):\n",
        "    '''\n",
        "    Inputs: \n",
        "        X: a matrix of dimension (m,n) where the columns are the English embeddings.\n",
        "        Y: a matrix of dimension (m,n) where the columns correspong to the French embeddings.\n",
        "        R: a matrix of dimension (n,n) - transformation matrix from English to French vector space embeddings.\n",
        "    Outputs:\n",
        "        g: a scalar value - gradient of the loss function L for given X, Y and R.\n",
        "    '''\n",
        "    ### START CODE HERE ###\n",
        "    # m is the number of rows in X\n",
        "    m = X.shape[0]\n",
        "\n",
        "    # gradient is X^T(XR - Y) * 2/m    \n",
        "    gradient = np.dot(X.T, (np.dot(X,R)-Y))*(2/m)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    return gradient"
      ],
      "metadata": {
        "id": "IIXKPdC_Zqx1"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def align_embeddings(X, Y, train_steps=100, learning_rate=0.0003, verbose=True, compute_loss=compute_loss, compute_gradient=compute_gradient):\n",
        "    '''\n",
        "    Inputs:\n",
        "        X: a matrix of dimension (m,n) where the columns are the English embeddings.\n",
        "        Y: a matrix of dimension (m,n) where the columns correspong to the French embeddings.\n",
        "        train_steps: positive int - describes how many steps will gradient descent algorithm do.\n",
        "        learning_rate: positive float - describes how big steps will  gradient descent algorithm do.\n",
        "    Outputs:\n",
        "        R: a matrix of dimension (n,n) - the projection matrix that minimizes the F norm ||X R -Y||^2\n",
        "    '''\n",
        "    np.random.seed(129)\n",
        "\n",
        "    # the number of columns in X is the number of dimensions for a word vector (e.g. 300)\n",
        "    # R is a square matrix with length equal to the number of dimensions in th  word embedding\n",
        "    R = np.random.rand(X.shape[1], X.shape[1])\n",
        "\n",
        "    for i in range(train_steps):\n",
        "        if verbose and i % 25 == 0:\n",
        "            print(f\"loss at iteration {i} is: {compute_loss(X, Y, R):.4f}\")\n",
        "        ### START CODE HERE ###\n",
        "        # use the function that you defined to compute the gradient\n",
        "        gradient = compute_gradient(X,Y,R)\n",
        "\n",
        "        # update R by subtracting the learning rate times gradient\n",
        "        R -= learning_rate*gradient\n",
        "        ### END CODE HERE ###\n",
        "    return R"
      ],
      "metadata": {
        "id": "WcLNWEPja8Ab"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "R_train = align_embeddings(X_train, Y_train, train_steps=400, learning_rate=0.8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFPiOqxBbPjL",
        "outputId": "4a6c3ce3-6a55-427f-e73f-101563d5ed49"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss at iteration 0 is: 963.0146\n",
            "loss at iteration 25 is: 97.8292\n",
            "loss at iteration 50 is: 26.8329\n",
            "loss at iteration 75 is: 9.7893\n",
            "loss at iteration 100 is: 4.3776\n",
            "loss at iteration 125 is: 2.3281\n",
            "loss at iteration 150 is: 1.4480\n",
            "loss at iteration 175 is: 1.0338\n",
            "loss at iteration 200 is: 0.8251\n",
            "loss at iteration 225 is: 0.7145\n",
            "loss at iteration 250 is: 0.6534\n",
            "loss at iteration 275 is: 0.6185\n",
            "loss at iteration 300 is: 0.5981\n",
            "loss at iteration 325 is: 0.5858\n",
            "loss at iteration 350 is: 0.5782\n",
            "loss at iteration 375 is: 0.5735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "R_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEa-mV_UbUJL",
        "outputId": "8777e83a-6bb7-4316-fef0-2a341e716eb2"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing K nearest neighbor based on cosine similarity to find nearest word in french to our prediction"
      ],
      "metadata": {
        "id": "F7Jof1a7eYtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nearest_neighbor(v, candidates, k=1, cosine_similarity=cosine_similarity):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "      - v, the vector you are going find the nearest neighbor for\n",
        "      - candidates: a set of vectors where we will find the neighbors\n",
        "      - k: top k nearest neighbors to find\n",
        "    Output:\n",
        "      - k_idx: the indices of the top k closest vectors in sorted form\n",
        "    \"\"\"\n",
        "    ### START CODE HERE ###\n",
        "    similarity_l = []\n",
        "\n",
        "    # for each candidate vector...\n",
        "    for row in candidates:\n",
        "        # get the cosine similarity\n",
        "      cos_similarity = cosine_similarity(v, row)\n",
        "        # append the similarity to the list\n",
        "      similarity_l.append(cos_similarity)\n",
        "\n",
        "    # sort the similarity list and get the indices of the sorted list    \n",
        "    sorted_ids = np.argsort(similarity_l)  \n",
        "    \n",
        "    # Reverse the order of the sorted_ids array\n",
        "    sorted_ids = sorted_ids[::-1]\n",
        "    # get the indices of the k most similar candidate vectors\n",
        "    k_idx = sorted_ids[:k]\n",
        "    ### END CODE HERE ###\n",
        "    return k_idx"
      ],
      "metadata": {
        "id": "8cCNGvlcep2q"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the accuracy"
      ],
      "metadata": {
        "id": "6phC9tGVfb9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_vocabulary(X, Y, R, nearest_neighbor=nearest_neighbor):\n",
        "    '''\n",
        "    Input:\n",
        "        X: a matrix where the columns are the English embeddings.\n",
        "        Y: a matrix where the columns correspong to the French embeddings.\n",
        "        R: the transform matrix which translates word embeddings from\n",
        "        English to French word vector space.\n",
        "    Output:\n",
        "        accuracy: for the English to French capitals\n",
        "    '''\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    # The prediction is X times R\n",
        "    pred = np.dot(X,R)\n",
        "\n",
        "    # initialize the number correct to zero\n",
        "    num_correct = 0\n",
        "\n",
        "    # loop through each row in pred (each transformed embedding)\n",
        "    for i in range(len(pred)):\n",
        "        # get the index of the nearest neighbor of pred at row 'i'; also pass in the candidates in Y\n",
        "        pred_idx = nearest_neighbor(pred[i], Y, k=1)\n",
        "\n",
        "        # if the index of the nearest neighbor equals the row of i... \\\n",
        "        if pred_idx == i:\n",
        "            # increment the number correct by 1.\n",
        "            num_correct += 1\n",
        "\n",
        "    # accuracy is the number correct divided by the number of rows in 'pred' (also number of rows in X)\n",
        "    accuracy = num_correct/pred.shape[0]\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "zr4T2wzxfeDf"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val, Y_val = get_matrices(en_fr_test, fr_embeddings_subset, en_embeddings_subset)"
      ],
      "metadata": {
        "id": "WwEBv_EWflS0"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = test_vocabulary(X_val, Y_val, R_train)\n",
        "print(f\"accuracy on test set is {acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuG-JUpdoi3c",
        "outputId": "deae9582-6811-4b54-9f00-024ff6226227"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on test set is 0.557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Machine Translation to translate some english words:"
      ],
      "metadata": {
        "id": "MnVy5Rn9g1qA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fr_embed_lst = [value for key,value in fr_embeddings_subset.items()]\n",
        "fr_lst = [key for key,value in fr_embeddings_subset.items()]\n",
        "en_lst = [key for key,value in en_embeddings_subset.items()]"
      ],
      "metadata": {
        "id": "j7pkLwXgkGyz"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v = np.dot(X_train[120:135], R_train)"
      ],
      "metadata": {
        "id": "Ye7T6d5Cg0r4"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(v.shape[0]):\n",
        "  print(en_lst[i]+' : ', end='')\n",
        "  print(fr_lst[nearest_neighbor(v[i], fr_embed_lst, 2)[0]]+', ', end = '')\n",
        "  print(fr_lst[nearest_neighbor(v[i], fr_embed_lst, 2)[1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx_9edTIi9ds",
        "outputId": "ba6d2dc4-8a2a-4a1d-c052-9dba1239fabe"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the : ces, mais\n",
            "was : élevé, faibles\n",
            "for : mais, ainsi\n",
            "that : district, ville\n",
            "with : mais, toujours\n",
            "from : suggestions, commenter\n",
            "this : mais, effectivement\n",
            "utc : football, soccer\n",
            "his : musique, chansons\n",
            "not : effectivement, mais\n",
            "are : configuration, paramétrage\n",
            "talk : siècles, décennies\n",
            "which : ligue, clubs\n",
            "also : éditer, modifications\n",
            "were : débat, débats\n"
          ]
        }
      ]
    }
  ]
}